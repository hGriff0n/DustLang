
Table Declaration
	[ <entry> ', ' ] where <entry> = '<id>:' <expr>
	The 'key' defaults to the next value of the range [1..] that is not already a key in the table
		Note that tables are 1 indexed by default
			Table keys can take on any value, this is only an assumption for the sake of standardization
			This behavior can be modified in-language by redefining global functions/metamethods
	Entries
		The last comma in a table's entry list is optional
		Table entry lists do not function like multiple assignment (no <key>, <key>: <value>, <value>)
			This does mean that you can refer to previous table fields for variable assignment (???)
				ie. [ x: 3, y: x + 3 ] = [ x: 3, y: 6 ]

Table Sub-types
	Arrays
		Table with only a contiguous subset of integers as keys
	Sets
		Table with only numeric keys
	Global/Scope

Table access
	Table values are accessed through the '.' and '[]' characters
		Currently t.1 = t[1] (this may change to t.1 = t["1"])
			Easier to implement '.' as a sugar for string literals than for string and int literals
			A workaround could be to convert strings to numbers if possible when used with '.'
				t.1 = t[1] but t.x = t["x"]
				How often are string numeral keys used anyways
		Accessing a table with a variable can only be performed through t[<var>]
			Using '.' syntax would translate to t.<var> = t["$var"]

	Could it be possible to restrict the type of keys/values a table will support
		ie. specify a table "array" so that array.s throws a type error but array[1] doesn't
		This will allow globals to be "table" values as in Lua and the language spec to be consistent

Set Comprehension Syntax (In order of current preference. Only 1 will be valid syntax)
	mult: [\x,y -> * | x in l, y in r, true]		## current favorite
	mult: [\ -> x*y | x in l, y in r, true]			## possible elision (if captures are implemented)
	mult: [x * y | x in l, y in r, true]			## haskell derived (possible sugar for the above (drop '\->') or some other implementation)

Table/Set operatiors
	Currently it is valid to perform an operation of Table + Int (ie. [] + 3 = [3])
		In these cases the non-table type is implicitly converted to a Table whose sole element is the non-table value.
		These operations are not exactly well defined on tables though
			When dealing with multiple elements with the same value, is this multiplicity removed or maintained (see Subtraction)

	## From viewing the Stanford Compiler course. A + B reads "union of A and B" in regexs

	Addition (+)								## Appends the elements from one table to the other
		I'm pretty sure this would have to be system defined
		I don't think this is entirely possible to implement in Dust (aside from calling an api function)

	Subtraction (-)								## Removes all elements of one table from the other
		Need to decide whether [2,2] - [2] should give [2] or []
			Should (t + t) - t = t if t = [2]
			t + (t - t) = t no matter how op-/op+ are defined

		\l, r -> [\x | x in l, !r.has(x)]			## [2,2] - [2] = []
		def op-(l <- Table, r <- Table)				## [2,2] - [2] = [2] ([2] - [2,2] will cause errors though)
			for x in r l:-x							## (for x in r l:- x) and l ???
			return l

	Union (&)									## Takes the union of two tables
		\l,r -> l + (r - l)						## I think [2] & [2] = [2]

	Intersection (^)							## Takes the intersection of two tables (elements that both have in common)
		\l,r -> l - (l - r)
		## \l,r -> [\x | x in l, r.has(x)].flatten

	Reduce (???)
		If [2,2] - [2] = [] then it would be helpful to have an operator/method to remove all duplicates in a table

	Splat (*)									## ala Ruby. Subject to change as it's very similar to multiplication
		x, y: *[2, 2]							## equivalent to x, y: 2, 2
		*x: 2, 2								## equivalent to x: [2, 2]
		I'm pretty sure this would have to be system defined

Set Ranges
	Syntax
		[<start>', <second>'..'<stop>'', <lambda>']

	I'm using the same symbol for ranges and tables
		Technically ranges are just converted to tables
			They might be instead converted to generators if they are accepted
			The syntax is just an easy way to specify a large series of value

	[1..10] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]										## Range syntax: [<start>(,second)..(stop)(, lambda)]
	[1,3..10] = [1, 3, 5, 7, 9]														## Custom range increments can be inferred by stating the second value
	[1..] = [1, 2, 3, 4, 5, ....]													## Ranges can be infinite (iff lazy evaluation is implemented)
	[10..1] = [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]										## Sign increments can be inferred automatically
	[1..28, \x -> x^2] = [1, 4, 9, 16, 25]											## Algorithmic steps can be specified by a function (that does what ???)
	## what about open interval ranges? ie. [1..10) = [1, 2, 3, 4, 5, 6, 7, 8, 9]

	Could I possibly generalize this rule to any type???
		ie. ['a'..'e'] = ['a', 'b', 'c', 'd', 'e']

		I could set some restrictions (somewhat like Haskell/Function Overloading)

Pattern Matching (Table specific syntax)
	def add([x, y])
		x + y

	This is (roughly) equivalent to			## Doesn't care about input size
		def add(t <- Table)
			(\x, y -> x + y)(*t)			## Note that pattern matching (in this case) is just syntactical sugar

		This pattern will only match arrays of size 0, 1, or 2 (provided a pattern is not provided for those)
			It could be possible to define some functions that would accept non-arrays but I don't know how that would be well defined/consistent
			If an array of size 0 or 1 is passed, than the leftover "args" are assigned nil (much like normal function arg assignment)

		It is possible to have a pattern that accepts arrays of size 3+	using the splat operator
			def add([x, y, *_])

	Way to keep a reference to the original list?
		def orig(t: [x, y, _*])			## I don't think this works

	Can pattern matching be used in variable assignment
		t: [1, 2]
		[x, y]: t						## equivalent to x, y: *t

		If I write the code to enable the syntax in either setting, I have the code to enable it in the other

Metamethods (another term ???)
	What are metamethods
		Certain functions that allow the interpreter/programmer to customize/define the behavior of certain syntax elements on tables (see Lua)
			For example, accessing a table will be routed through the '__index' metamethod
		It could be possible to have meta-metamethods (functions that modify metamethods, ie. '__memoize' in the memorization examples)

	factorial: [						## This memorization table for the computation of factorials (see NeatTricks for more info)
		0: 1,							## However through metamethods, the syntax for table access/assignment doubles as a function "call"
		__memoize: \x ->				## This defines the memoization function
			if x < 0, return nil		## But it also modifies the table (See NeatTricks.txt)
			x *	factorial[x - 1],
		__call: \x -> factorial[x]		## Validates 'factorial(4)' syntax. Only syntactical sugar in the long run
	]

	Should a prefix (ala '__') to metamethods be enforced or optional (and should it prefered in this case)
		__call, __memoize, __index, __newindex
		op+, op-, op&, op^, op<, op>, op= etc.		## Note that <= can be defined as \x,y -> x < y or x = y

	How to refer to the table (when referring to table keys/fields inside of the table)
		'self' keyword
			This can be done implicitly through scoping
		Can also refer to the table by name
			This runs into some problem with scoping/reassignment

Interaction between tables and constant-ness (Metamethods and 'let' syntax)
	Entries can be added but not changed (see NeatTricks memoize example)
		Use 'let' fields								## Generalization of the constant declarization rules (they're not exactly defined though)
			const_table: [ let x: 5	]

		For a more generalized (ie. table-wide) behavior
			__newindex: \x,y -> y and (let self[x]: y)		## wouldn't this call __newindex ???

		Or disable reassignment
			__index: \x -> self[x]						## const_table.x: 3 is const_table.__index("x", 3)

	Entries can be changed but not added
		Disable assignment by redefining the __newindex metamethod
			fixed_table: [
				__newindex: \ -> nil					## fixed by proxy
				__newindex: noAssign					## __newindex: nil (ie. is nil(x, y) valid syntax/semantics ???)
			]

	Entries can not be added or changed
		Use 'let' syntax (declare the table with let)	## This solution could also solve P1 behavior (most languages treat this as such)
			let immutable_table: []						## I feel that this option is simpler and more consistent however
		Disable reassignment and assignment by redefining __index and __newindex
			This is a combination to the above "solutions" 

	Can possibly extract some of the specific details to some outside function/factory/flag/metatmethod
		Automates the process of disabling __newindex/__index as shown in the first two solutions

What about multi-dimensional tables (ie. matrices) ??? [i,j] vs. [i][j]. See LCS for comparison between the two
	[i][j] syntax
		It is a standard syntax accross programming languages
		It is guaranteed to be valid and semantically defined in dust as being the sequential access of nested tables

	[i,j] syntax
		It is similar to the typical written syntax for matrices
		As demonstrated in LCS, it could make most memorization problems trivial to implement
		However it would most likely be a form of syntactical sugar (more difficult to implement)
			Easiest implementation would be to have tables as keys which has its own problems (ie. should [1,2] = [i,2] if i = 1, see Lua)

	See LCStests.txt for Longest Common Subsequence implemented in [i][j] and [i,j] syntax

In-line Multiline lambdas (where do blocks end???)
	Try to make it so that a multi-lined lambda only needs the default table seperator to be defined inline.
		Consider alternate syntax or restrictions if it is no possible

	test: [
		hello: \x ->
			if x <- String
				print("Hello " + x),				## hopefully this comma (and the indentation difference) is enough
		goodbye: \ -> print "Goodbye",
		op+: \x -> "Your name is " + x
	]

Table functions
	size(table)				## or go like Lua and have a size operator (op#)
	entries(table)			## returns a new table filled with the entries of the passed table (ie. entries(t).i = [i, t.i], roughly)
	flatten/smooth(table)	## Removes nesting in a list
	next(table, idx)		## Returns the next index (ie. t: [ 1, 2, 3, 5: 5 ]; next(t, 1) = t[2]; next(t, 4) = t[5])

	def reduce(t <- Table, fn <- Function, sum)
		if !sum sum, t: fst(t), tail(t)
		for x in t @sum: fn(x, sum)
		sum													## is this line necessary or would the function return sum regardless (ie. what is the value of a for loop)

	def replicate(item, n <- Number)						## replaces 'fill'
		if n <= 0 return []
		if n = 1 return [item]
		replicate(item, floor(n / 2)) + item + replicate(item, ceil(n / 2))

	has: \t,v -> t ^ v
	map: \t,fn -> [\x -> fn(x) | x in t]
	sum: \t -> t.reduce(\x, s -> x + s)
	entries: \t -> t.zip(t.keys, t.values)					## Might change the naming. Also, t.1 gives the key as opposed to t.key 

Have a syntax/ability to perform python-like slices???
	Python code: arr[:n]	get the first n items
				 arr[i:i+n] get the first n items starting at i
				 arr[i:n]	get the subarray from i to n (not actually python syntax)

	Could arr[i,j] be an slice (with a __slice metamethod) ???

## repl.it